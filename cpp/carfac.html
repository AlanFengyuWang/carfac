<html>
<head>
<title>CARFAC</title>
<script src="carfac.js"></script>
<script>
function InitWebAudio() {
  context = new webkitAudioContext();
  console.log("sampleRate = " + context.sampleRate);
  console.assert(context.sampleRate == 44100);

  // Use as a (not very good) anti-aliasing filter.
  antiAliasFilterNode = context.createBiquadFilter();
  antiAliasFilterNode.frequency = 8000;  // Hertz.
  antiAliasFilterNode.Q = 0;

  InitInputNodes(context, antiAliasFilterNode);

  // Control the input level with a slider.
  gainNode = context.createGainNode();
  document.getElementById('input_gain').onchange =
    function () { gainNode.gain.value = this.value; };
  antiAliasFilterNode.connect(gainNode);

  saiNode = CreateSAINode(context);
  gainNode.connect(saiNode);

  // Hook up the sound output.
  saiNode.connect(context.destination);
}

function InitInputNodes(context, antiAliasFilterNode) {
  var inputNodes = [
    context.createMediaElementSource(document.getElementById('test_audio')),
    null,  // Microphone source, Initialized below.
  ];
  inputNodes[0].connect(antiAliasFilterNode);

  navigator.webkitGetUserMedia(
      {audio: true},
      function(e) {
        // Microphone input available.
        inputNodes[1] = context.createMediaStreamSource(e);
      },
      function(e) {
        // Microphone input unavailable.
        console.log(e);
        alert('Error accessing microphone:\n' + e);
      });

  // Input selector controls.
  function selectInputNode(i) {
    inputNodes[1 - i].disconnect();
    inputNodes[i].connect(antiAliasFilterNode);
  }
  document.getElementById('test_input').onclick =
      function() { selectInputNode(0); };
  document.getElementById('mic_input').onclick =
      function() { selectInputNode(1); };
}

function CreateSAINode(context) {
  var bufferSize = 2048;
  var saiNode = context.createScriptProcessor(bufferSize,
                                              1,  // numInputChannels
                                              1);  // numOutputChannels

  // Configure the canvas element that the SAIPlotter will render to.
  Module.canvas = document.getElementById('sai_canvas');

  // TODO(ronw): Add some controls (and hooks in the C++ class) to
  // allow users to configure the various CARFAC and SAI params.

  // The input will be downsampled by a factor of two before being
  // passed into the SAIPlotter.
  var saiPlotter = new Module.SAIPlotter(context.sampleRate / 2,
                                         bufferSize / 2);
  var sampleBuffer = Module._malloc(4 * bufferSize / 2);
  saiNode.onaudioprocess = function (e) {
    var buffer = e.inputBuffer.getChannelData(0);

    // Copy the audio samples to the output so it can be sent to the sound
    // output.
    e.outputBuffer.getChannelData(0).set(buffer);

    // var energy = 0;
    for (var i = 0; i < buffer.length; i += 2) {
      // energy += buffer[i] * buffer[i];
      // Decimate by a factor of two before calling CARFAC.
      HEAPF32[(sampleBuffer >> 2) + i / 2] = buffer[i];
    }
    // console.log(e.timeStamp + ": energy = " + energy);

    var sampleBufferLength = buffer.length / 2;
    saiPlotter.ComputeAndPlotSAI(sampleBuffer, sampleBufferLength);
  };

  return saiNode;
}

</script>
</head>
<body onload="InitWebAudio();">
  <canvas id="sai_canvas"></canvas>
  <br>
  Select input:
  <br>
  <input type="radio" name="input_selector" id="test_input" checked> test sound
  <audio src="../test_data/long_test.wav"
         controls="controls"
         id="test_audio"/>
  </audio>
  <br>
  <input type="radio" name="input_selector" id="mic_input"> microphone
  <br>

  <br>
  Input gain:
  <input id="input_gain" type="range" min="0" max="1" step="0.01" value="1"/>
</script>

</body>
</html>
